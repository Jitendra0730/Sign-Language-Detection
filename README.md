
#  Sign Language Detection & Translation (Aâ€“Z)

A real-time hand sign recognition app that detects alphabets (Aâ€“Z) using webcam input and a trained machine learning model. It includes a Tkinter GUI, voice feedback, and sentence assembly from recognized gestures.

---

## ğŸ“¸ Demo Preview

![Screenshot](./screenshot.png)  
*Live webcam feed, prediction display, and Speak/Clear/Start/Stop buttons.*

---

## ğŸ’¡ Features

- âœ… Real-time **hand sign recognition** (Aâ€“Z) using MediaPipe
- ğŸ”Š **Text-to-speech** for predicted alphabets
- ğŸ–¥ï¸ **Tkinter GUI** with:
  - Start/Stop Webcam
  - Speak Prediction
  - Clear Assembled Sentence
- ğŸ§  Machine Learning Model trained on 21 hand landmarks (x, y) = 42 features

---

## ğŸ› ï¸ Technologies Used

| Module       | Purpose                            |
|--------------|-------------------------------------|
| MediaPipe     | Hand landmark detection             |
| OpenCV        | Webcam access and image processing  |
| Tkinter       | GUI creation                        |
| Joblib        | Model persistence                   |
| NumPy         | Data processing                     |
| pyttsx3       | Text-to-speech                      |

---

## ğŸ“ Project Structure

```
Sign-Language-Detection/
â”œâ”€â”€ collect_data.py           # Collects hand landmark data
â”œâ”€â”€ training.py               # Trains the model
â”œâ”€â”€ sign_language_model.pkl   # Trained model and LabelEncoder
â”œâ”€â”€ sign_language_data.csv    # Dataset with landmarks and labels
â”œâ”€â”€ a_to_z_prediction.py      # Command-line prediction script
â”œâ”€â”€ prediction.py             # GUI with voice and sentence features
â”œâ”€â”€ screenshot.png            # App screenshot
```

---

## ğŸ§ª How to Use

### 1. Install Dependencies

```bash
pip install opencv-python mediapipe numpy pyttsx3 joblib
```

### 2. Run the GUI Application

```bash
python prediction.py
```
